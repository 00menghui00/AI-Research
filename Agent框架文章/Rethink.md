# Rethink框架
“Rethink 强提示”指在单一 Agent 框架下，通过精心设计的高质量 Prompt（包括角色设定、示例演示、链式思考指令等），使单一模型在带示例（demonstration）的场景中，其性能几乎能够匹配最优的多智能体讨论（Multi-Agent Discussion）方法。这种做法强调在 Prompt 层面投入，能以极低的架构复杂度实现与多 Agent 框架相当的推理效果。

- 论文：Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?

---
---
---

# Don’t Build Multi-Agents
博文地址：https://cognition.ai/blog/dont-build-multi-agents#a-theory-of-building-long-running-agents

- “提示工程”是一个术语，指的是需要以适合 LLM 聊天机器人的理想格式编写你的任务。 “上下文工程”是这一步的下一级别。它是在动态系统中自动执行这项工作。它需要更多的细微差别，并且实际上是构建 AI 代理工程师的首要工作。
- 提出两个原则（Principles of Context Engineering）

## A Theory of Building Long-running Agents
- 当代理在长时间运行时必须保持可靠并维持连贯的对话时，你必须做某些事情来控制潜在的错误累积。否则，如果你不小心，事情很快就会崩溃。
- 大多数现实世界的任务都有许多层次的细微差别，所有这些都有可能被误解。你可能认为一个简单的解决方案是仅仅将原始任务作为上下文复制到子代理中。这样，他们就不会误解自己的子任务。但请记住，在一个真实的生产系统中，对话很可能是多轮的，代理可能不得不进行一些工具调用来决定如何分解任务，而且任何数量的细节都可能对任务的解释产生影响。

### Context Engineering（上下文工程）

共享上下文，并共享完整的代理跟踪记录，而不仅仅是单个消息

### Actions carry implicit decisions（行为隐含决策）

行为隐含着决策，而冲突的决策会导致不良后果

### 单线程线性代理
原则 1 和 2 至关重要，且极少有必要违反，因此你应该默认排除任何不遵守这些原则的智能体架构。你可能会认为这很限制，但实际上，你仍然可以探索许多不同的智能体架构。遵循原则最简单的方法就是只使用单线程线性代理。

### Applying the Principles
截至 2025 年 6 月，Claude Code 是一个会生成子任务的智能体。然而，它从不与子任务智能体并行工作，而且子任务智能体通常只被分配回答问题，而不是编写任何代码。为什么？子任务智能体缺乏来自主智能体的上下文，否则它将无法做任何超出回答一个明确定义的问题之外的事情。而且，如果它们运行多个并行子智能体，它们可能会给出冲突的响应，导致我们之前看到的智能体可靠性问题。在这种情况下，拥有一个子智能体的好处是，所有子智能体的调查工作都不必保留在主智能体的历史记录中，从而允许在上下文用尽之前运行更长的跟踪。Claude Code 的设计者采取了故意简单的方法。
