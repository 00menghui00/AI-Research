# FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness（2022）
- 论文地址：https://ar5iv.labs.arxiv.org/html/2205.14135?_immersive_translate_auto_translate=1

## 概述：
- flashattention并没有改变attention架构本身，而是通过IO感知加速标准注意力在GPU上的计算
