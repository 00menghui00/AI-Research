# Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context(2019)
- 论文地址：https://ar5iv.labs.arxiv.org/html/1901.02860?_immersive_translate_auto_translate=1
- 
