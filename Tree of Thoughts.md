# Tree of Thoughts: Deliberate Problem Solving with Large Language Models
原文地址：https://arxiv.org/html/2305.10601?_immersive_translate_auto_translate=1

## 概念梳理：

### 1. “语言模型在推理过程中仍然局限于令牌级、从左到右的决策过程”

#### 1. 令牌级 (Token-level)：
- 含义： 在大型语言模型中，文本不是以字符或单词为单位处理的，而是以“令牌”（Token）为单位。一个令牌可能是一个单词、一个词的一部分、一个标点符号，甚至是一个空格。例如，“Hello world!” 可能被分解为 ["Hello", " world", "!"] 三个令牌。
- 决策过程： LLM 的核心任务是预测下一个最有可能的令牌。它在每一步都根据到目前为止已经生成的所有令牌来计算下一个令牌的概率分布，然后从中选择一个（通常是概率最高的，或者通过采样选择）。

#### 2. 从左到右 (Left-to-right)：
- 含义： 这指的是模型生成文本的方向和顺序。LLM 是一种“自回归”（autoregressive）模型，这意味着它总是从序列的开头（左侧）开始生成，并逐步向后（右侧）生成。它生成一个令牌，然后将这个新生成的令牌添加到输入序列中，再预测下一个令牌，如此循环，直到生成结束符或达到最大长度。
- 决策过程： 每一次预测下一个令牌的“决策”，都是基于它前面已经生成的所有令牌。它无法“跳到”序列的中间或末尾去预先规划，也无法在生成过程中轻易地“回溯”到前面已经生成的令牌并修改它们。
