# A Survey on LLM-as-a-Judge （评分LLM综述论文）
论文地址：https://arxiv.org/html/2411.15594?_immersive_translate_auto_translate=1

近期研究表明，LLM-as-a-Judge这一理念能够将自动方法的可扩展性与专家判断中发现的细致、上下文敏感的推理相结合（Zheng 等人，2023b；Wang 等人，2023c；Zhu 等人，2023a；Li 等人，2023b；Chen 等人，2024c）。此外，在适当的提示学习或微调（Khattak 等人，2023）下，LLMs 可能变得足够灵活，以处理多模态输入（Chen 等人，2024b）。这些优势表明，LLM-as-a-Judge 方法可能作为一种新颖且广泛适用的范例，用于解决复杂和开放式的评估问题。

## 1. In-Context Learning
要应用 LLM-as-a-Judge，评估任务通常使用情境学习方法来指定，这些方法提供指令和示例来指导模型的推理和判断。这个过程涉及两个关键方面：输入设计和提示设计。对于输入设计，需要考虑要评估的变量类型（如文本、图像或视频）、输入方式（例如单独、成对或批量）及其位置（例如在开头、中间或结尾）。对于提示设计，可以采用四种不同的方法，这些方法包括生成分数、解决真/假问题、进行成对比较和进行多项选择。

### 1.1 Generating scores
使用相应的分数来表示评估非常直观。然而，需要更仔细考虑的是用于评估的分数的性质和范围。分数可以是离散的，常见的范围如 1-3、1-5（Jones 等人，2024 年）或 1-10（Zhu 等人，2023a；Li 等人，2023b）。或者，它可以是连续的，范围从 0 到 1 或 0 到 100（Xiong 等人，2024 年）。最简单的方法是通过上下文来评分，设定分数范围和主要评分标准。例如，“请评价其回答的有用性、相关性、准确性、细节程度。每位助手在 1 到 10 的量表上获得一个总分，其中较高的分数表示更好的整体表现”（Zhu 等人，2023a）。稍微复杂一点的方法是提供更详细的评分标准。更复杂的评分情况可以是语言模型作为考官（Bai 等人，2023 年），它使用李克特量表评分函数作为绝对评估指标。评估者根据预定义的维度（包括准确性、连贯性、事实性和全面性）给给定的回答打分。每个维度都在 1 到 3 的量表上评分，从最差到最好。同时，要求评估者根据先前分配给 4 个维度的分数，提供一个 1 到 5 的总体评分。这个分数作为衡量答案整体质量的一个指标。

### 1.2 Solving Yes/No questions
- 一个是/否问题需要对给定陈述进行判断，仅关注其准确性。这类问题简单直接，只提供两种固定回答——是或否，真或假——没有任何额外的比较或选择。
- 此类评估常用于中间过程，为反馈循环创造条件。例如，它促进了自我优化循环，如 Reflexion（Shinn 等人，2023 年）所示，该模型通过生成语言自我反思来为未来的尝试提供有价值的反馈。在稀疏奖励信号的场景中，例如二元成功状态（成功/失败），自我反思模型利用当前轨迹和持久记忆来生成细致且具体的反馈。类似地，在自我改进环境中（Tian 等人，2024 年），可以使用 Yes/No 问题来评估自定义短语，如"需要修改"和"不需要修改"，从而促进进入下一循环。此外，这些评估常用于测试知识准确性，并评估陈述是否与既定事实一致（Sun 等人，2023c），例如：“给定一个问题及其相关的检索知识图谱三元组（实体、关系、实体），要求你回答这些三元组和你的知识是否足以回答该问题（是或否）。”

### 1.3 Conducting pairwise comparisons
- 两两比较是指比较两个选项并选择哪一个更优越或更符合特定标准。它涉及在两个选项之间做出决策，而不是在“是”或“否”之间进行判断。这种比较可以是主观的，也可以基于客观标准。这种评估是相对评估。两两比较通常用于对多个选项进行排序或确定优先级，其中通过在成对之间进行多次比较来识别更好的选择或建立等级。
- 两两比较是一种已建立的方法，对多个领域产生了显著影响（Qin 等人，2024a）。正如（Liu 等人，2024b）所指出的，在两两比较的背景下，LLM 和人类评估比基于分数的评估更为一致。大量研究表明，在位置一致性方面，两两比较评估优于其他评判方法（Zheng 等人，2023b；Liusie 等人，2024）。此外，两两比较可以通过使用高级排序算法（Qin 等人，2024a；Liu 等人，2024b）、数据过滤（Yuan 等人，2023b）等方法扩展到更复杂的基于关系评估框架，如列表比较。在两两比较评估中，作为评判者的 LLM 被提示选择能更好地回答当前问题的回答。为了适应平局的可能性，引入了多种选项模式。两选项模式要求评判者从两个给定选项中选择更好的回答。三选项模式引入了额外的选择，允许评判者在两个回答都不更优时表示平局。

### 1.4 Making multiple-choice selections
- 多项选择题涉及提供多个选项，而非进行成对比较的相对选择，也不是进行是非判断。评价者必须选择最恰当或正确的一个。与判断题相比，这种方法允许更广泛的回答范围，可以评估更深入的理解或偏好。

## 2. Model Selection
### 2.1 General LLM
- 为了通过 LLM-as-a-Judge 实现评估自动化，一种有效的方法是采用先进的语言模型，如 GPT-4（OpenAI，2023），而不是人工评估员（Zheng 等人，2023b）。研究表明，基于 GPT-4 的评估器的准确性高于专业人工评估员，在评估中表现出更高的一致性和稳定性。同时，如果所使用的通用 LLM 在指令遵循或推理能力方面存在局限，LLM-as-a-Judge 方法的有效性可能会受到显著影响。

### 2.2 Fine-tuned LLM
- 然而，依赖外部 API 进行评估可能会引发隐私泄露的考量，且 API 模型的不可透明性也挑战了评估的可重复性。因此，后续研究建议通过强调成对比较或评分的使用来优化专为评估设计的语言模型。例如，PandaLM（Wang 等人，2023c）基于 Alpaca 指令和 GPT-3.5 标注构建数据，然后微调 LLaMA-7B（Touvron 等人，2023a）作为评估模型。JudgeLM（Zhu 等人，2023a）从多样化的指令集和 GPT-4 标注中构建数据，并微调 Vicuna（Touvron 等人，2023b）作为可扩展的评估模型。Auto-J（Li 等人，2023b）在多种场景下构建评估数据以训练生成式评估模型，该模型可提供评估和批判性意见。Prometheus（Kim 等人，2023）定义了数千个评估标准，基于 GPT-4 构建反馈数据集，并微调细粒度评估模型。
- 微调判别模型的标准流程主要包括三个步骤。步骤 1：数据收集。训练数据通常由三个组成部分构成：指令、待评估对象和评估结果。指令通常来源于指令数据集，而评估结果可以来自 GPT-4 或人工标注。步骤 2：提示设计。提示模板的结构可以根据评估方案进行调整（见In-Context Learning章节）。步骤 3：模型微调。使用设计的提示和收集的数据，评估器的微调过程通常遵循指令微调范式（Ouyang 等人，2022 年）。模型接收一条指令以及一个或多个响应，以生成包含评估结果和可能解释的输出。
- 
