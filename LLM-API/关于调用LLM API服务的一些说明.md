# api调用规范

### LLM API 调用规范核心参数总结

| 参数分类 | 参数名 | 作用与规范 | 示例 |
| :--- | :--- | :--- | :--- |
| **核心** | `model` | **（必需）** 指定要使用的模型ID。 | `"gpt-4o"` |
| | `messages` | **（必需）** 对话历史列表，包含`role`和`content`。是与模型交互的核心。 | `[{"role": "user", "content": "你好"}]` |
| **输出格式** | `response_format` | **（强烈推荐）** 强制模型按指定格式输出，如JSON。极大提升可靠性。 | `{"type": "json_object"}` |
| **行为控制** | `temperature` | 控制输出的随机性（0.0-2.0）。`0`表示确定性高，适合精确任务。 | `0.5` |
| | `seed` | 随机种子。与`temperature`配合，实现可复现的输出，用于测试和调试。 | `42` |
| | `max_tokens` | 限制生成内容的最大长度，用于控制成本和响应时间。 | `1024` |
| | `top_p` | 核采样参数，另一种控制随机性的方式，通常不与`temperature`同时使用。 | `0.9` |
| **功能扩展** | `tools` / `tool_choice` | **（高级功能）** 允许模型调用外部函数或工具（Function Calling），实现更复杂的工作流。 | `[{"type": "function", ...}]` |
| | `stream` | **（可选）** 是否以流式（Streaming）方式返回结果，实现打字机效果，提升用户体验。 | `True` |

---

# 国内调用openai的api时会被墙，介绍如何解决被墙的问题

## 解决方案一：使用代理api

配置代理API_BASE即可，API_KEY保持不变（代理URL只是做了一个跳转，因此对KEY没有影响）
